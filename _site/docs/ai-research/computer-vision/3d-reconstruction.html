<!DOCTYPE html> <html lang="en-US"> <head> <meta charset="UTF-8"> <meta http-equiv="X-UA-Compatible" content="IE=Edge"> <link rel="stylesheet" href="/assets/css/just-the-docs-default.css"> <link rel="stylesheet" href="/assets/css/just-the-docs-head-nav.css" id="jtd-head-nav-stylesheet"> <style id="jtd-nav-activation"> .site-nav > ul.nav-list:first-child > li > a, .site-nav > ul.nav-list:first-child > li > ul > li > a, .site-nav > ul.nav-list:first-child > li > ul > li > ul > li:not(:nth-child(1)) > a, .site-nav > ul.nav-list:first-child > li > ul > li > ul > li > ul > li a { background-image: none; } .site-nav > ul.nav-list:not(:first-child) a, .site-nav li.external a { background-image: none; } .site-nav > ul.nav-list:first-child > li:nth-child(1) > ul > li:nth-child(3) > ul > li:nth-child(1) > a { font-weight: 600; text-decoration: none; }.site-nav > ul.nav-list:first-child > li:nth-child(1) > button svg, .site-nav > ul.nav-list:first-child > li:nth-child(1) > ul > li:nth-child(3) > button svg, .site-nav > ul.nav-list:first-child > li:nth-child(1) > ul > li:nth-child(3) > ul > li:nth-child(1) > button svg { transform: rotate(-90deg); }.site-nav > ul.nav-list:first-child > li.nav-list-item:nth-child(1) > ul.nav-list, .site-nav > ul.nav-list:first-child > li.nav-list-item:nth-child(1) > ul.nav-list > li.nav-list-item:nth-child(3) > ul.nav-list, .site-nav > ul.nav-list:first-child > li.nav-list-item:nth-child(1) > ul.nav-list > li.nav-list-item:nth-child(3) > ul.nav-list > li.nav-list-item:nth-child(1) > ul.nav-list { display: block; } </style> <script src="/assets/js/vendor/lunr.min.js"></script> <script src="/assets/js/just-the-docs.js"></script> <meta name="viewport" content="width=device-width, initial-scale=1"> <link rel="icon" href="/assets/images/favicon.ico" type="image/x-icon"> <!-- Begin Jekyll SEO tag v2.8.0 --> <title>3D Image Reconstruction | sanhan research</title> <meta name="generator" content="Jekyll v3.10.0" /> <meta property="og:title" content="3D Image Reconstruction" /> <meta property="og:locale" content="en_US" /> <meta name="description" content="Lesson 5" /> <meta property="og:description" content="Lesson 5" /> <link rel="canonical" href="http://localhost:4000/docs/ai-research/computer-vision/3d-reconstruction" /> <meta property="og:url" content="http://localhost:4000/docs/ai-research/computer-vision/3d-reconstruction" /> <meta property="og:site_name" content="sanhan research" /> <meta property="og:type" content="website" /> <meta name="twitter:card" content="summary" /> <meta property="twitter:title" content="3D Image Reconstruction" /> <meta name="google-site-verification" content="TumEYHq6xpSNuebLNUkEWUMOUm3w7a6mdrQ33DQPEwA" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"WebPage","description":"Lesson 5","headline":"3D Image Reconstruction","url":"http://localhost:4000/docs/ai-research/computer-vision/3d-reconstruction"}</script> <!-- End Jekyll SEO tag --> <!-- Copied from https://katex.org/docs/browser.html#starter-template --> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.3/dist/katex.min.css" integrity="sha384-Juol1FqnotbkyZUT5Z7gUPjQ9gzlwCENvUZTpQBAPxtusdwFLRy382PSDx5UUJ4/" crossorigin="anonymous"> <!-- The loading of KaTeX is deferred to speed up page rendering --> <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.3/dist/katex.min.js" integrity="sha384-97gW6UIJxnlKemYavrqDHSX3SiygeOwIZhwyOKRfSaf0JWKRVj9hLASHgFTzT+0O" crossorigin="anonymous"> </script> <!-- Automatically display code inside script tags with type=math/tex using KaTeX --> <script defer src="/assets/js/mathtex-script-type.js"> </script> <!-- To automatically render math in text elements, include the auto-render extension: --> <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.3/dist/contrib/auto-render.min.js" integrity="sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05" crossorigin="anonymous" onload="renderMathInElement(document.body, { globalGroup: true, trust: true, strict: false, throwOnError: false, });"></script> <!-- The KaTeX default is 1.21em, see https://katex.org/docs/font.html#font-size-and-lengths --> <style> .katex { font-size: 1em; } </style> </head> <body> <a class="skip-to-main" href="#main-content">Skip to main content</a> <svg xmlns="http://www.w3.org/2000/svg" class="d-none"> <symbol id="svg-link" viewBox="0 0 24 24"> <title>Link</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-link"> <path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path> </svg> </symbol> <symbol id="svg-menu" viewBox="0 0 24 24"> <title>Menu</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-menu"> <line x1="3" y1="12" x2="21" y2="12"></line><line x1="3" y1="6" x2="21" y2="6"></line><line x1="3" y1="18" x2="21" y2="18"></line> </svg> </symbol> <symbol id="svg-arrow-right" viewBox="0 0 24 24"> <title>Expand</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-chevron-right"> <polyline points="9 18 15 12 9 6"></polyline> </svg> </symbol> <!-- Feather. MIT License: https://github.com/feathericons/feather/blob/master/LICENSE --> <symbol id="svg-external-link" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-external-link"> <title id="svg-external-link-title">(external link)</title> <path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path><polyline points="15 3 21 3 21 9"></polyline><line x1="10" y1="14" x2="21" y2="3"></line> </symbol> <symbol id="svg-doc" viewBox="0 0 24 24"> <title>Document</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-file"> <path d="M13 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V9z"></path><polyline points="13 2 13 9 20 9"></polyline> </svg> </symbol> <symbol id="svg-search" viewBox="0 0 24 24"> <title>Search</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-search"> <circle cx="11" cy="11" r="8"></circle><line x1="21" y1="21" x2="16.65" y2="16.65"></line> </svg> </symbol> <!-- Bootstrap Icons. MIT License: https://github.com/twbs/icons/blob/main/LICENSE.md --> <symbol id="svg-copy" viewBox="0 0 16 16"> <title>Copy</title> <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-clipboard" viewBox="0 0 16 16"> <path d="M4 1.5H3a2 2 0 0 0-2 2V14a2 2 0 0 0 2 2h10a2 2 0 0 0 2-2V3.5a2 2 0 0 0-2-2h-1v1h1a1 1 0 0 1 1 1V14a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V3.5a1 1 0 0 1 1-1h1v-1z"/> <path d="M9.5 1a.5.5 0 0 1 .5.5v1a.5.5 0 0 1-.5.5h-3a.5.5 0 0 1-.5-.5v-1a.5.5 0 0 1 .5-.5h3zm-3-1A1.5 1.5 0 0 0 5 1.5v1A1.5 1.5 0 0 0 6.5 4h3A1.5 1.5 0 0 0 11 2.5v-1A1.5 1.5 0 0 0 9.5 0h-3z"/> </svg> </symbol> <symbol id="svg-copied" viewBox="0 0 16 16"> <title>Copied</title> <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-clipboard-check-fill" viewBox="0 0 16 16"> <path d="M6.5 0A1.5 1.5 0 0 0 5 1.5v1A1.5 1.5 0 0 0 6.5 4h3A1.5 1.5 0 0 0 11 2.5v-1A1.5 1.5 0 0 0 9.5 0h-3Zm3 1a.5.5 0 0 1 .5.5v1a.5.5 0 0 1-.5.5h-3a.5.5 0 0 1-.5-.5v-1a.5.5 0 0 1 .5-.5h3Z"/> <path d="M4 1.5H3a2 2 0 0 0-2 2V14a2 2 0 0 0 2 2h10a2 2 0 0 0 2-2V3.5a2 2 0 0 0-2-2h-1v1A2.5 2.5 0 0 1 9.5 5h-3A2.5 2.5 0 0 1 4 2.5v-1Zm6.854 7.354-3 3a.5.5 0 0 1-.708 0l-1.5-1.5a.5.5 0 0 1 .708-.708L7.5 10.793l2.646-2.647a.5.5 0 0 1 .708.708Z"/> </svg> </symbol> </svg> <div class="side-bar"> <div class="site-header" role="banner"> <a href="/" class="site-title lh-tight"> sanhan research </a> <button id="menu-button" class="site-button btn-reset" aria-label="Toggle menu" aria-pressed="false"> <svg viewBox="0 0 24 24" class="icon" aria-hidden="true"><use xlink:href="#svg-menu"></use></svg> </button> </div> <nav aria-label="Main" id="site-nav" class="site-nav"> <ul class="nav-list"><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in AI Research category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/docs/ai-research" class="nav-list-link">AI Research</a><ul class="nav-list"><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in ARC-AGI category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/docs/ai-research/arc-agi" class="nav-list-link">ARC-AGI</a><ul class="nav-list"><li class="nav-list-item"><a href="/docs/ai-research/arc-agi/dataset" class="nav-list-link">ARC-AGI dataset</a></li><li class="nav-list-item"><a href="/docs/ai-research/arc-agi/resarch-note" class="nav-list-link">Research on ARC-AGI</a></li></ul></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in LLM category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/docs/ai-research/llm" class="nav-list-link">LLM</a><ul class="nav-list"><li class="nav-list-item"><a href="/docs/ai-research/llm/utilizations" class="nav-list-link">LLM Utilizations</a></li><li class="nav-list-item"><a href="/docs/ai-research/llm/control-theory" class="nav-list-link">Control theory of LLM</a></li></ul></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Computer Vision category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/docs/ai-research/computer-vision" class="nav-list-link">Computer Vision</a><ul class="nav-list"><li class="nav-list-item"><a href="/docs/ai-research/computer-vision/3d-reconstruction" class="nav-list-link">3D Image Reconstruction</a></li></ul></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Machine Unlearning category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/docs/ai-research/unlearning" class="nav-list-link">Machine Unlearning</a><ul class="nav-list"><li class="nav-list-item"><a href="/docs/ai-research/unlearning/resarch-note" class="nav-list-link">Research on Machine Unlearning</a></li></ul></li></ul></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Programming category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/docs/programming" class="nav-list-link">Programming</a><ul class="nav-list"><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Algorithms and Data structures category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/docs/programming/algorithms" class="nav-list-link">Algorithms and Data structures</a><ul class="nav-list"><li class="nav-list-item"><a href="/docs/programming/algorithms/Useful%20Timer%20Class.html" class="nav-list-link">Useful Timer Class</a></li></ul></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Concurrent Programming category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/docs/programming/concurrent-programming" class="nav-list-link">Concurrent Programming</a><ul class="nav-list"><li class="nav-list-item"><a href="/docs/programming/concurrent-programming/01.%20Introduction.html" class="nav-list-link">01. Introduction</a></li><li class="nav-list-item"><a href="/docs/programming/concurrent-programming/02.%20Multitasking.html" class="nav-list-link">02. Multitasking</a></li><li class="nav-list-item"><a href="/docs/programming/concurrent-programming/03.%20Multiprocessing.html" class="nav-list-link">03. Multiprocessing</a></li><li class="nav-list-item"><a href="/docs/programming/concurrent-programming/04.%20Multithreading.html" class="nav-list-link">04. Multithreading</a></li><li class="nav-list-item"><a href="/docs/programming/concurrent-programming/05.%20IPC.html" class="nav-list-link">05. Inter-Process Communication (IPC)</a></li><li class="nav-list-item"><a href="/docs/programming/concurrent-programming/06.%20IPC-Message-Passing.html" class="nav-list-link">06. IPC - Message Passing</a></li><li class="nav-list-item"><a href="/docs/programming/concurrent-programming/07.%20IPC-Shared-Memory.html" class="nav-list-link">07. IPC - Shared Memory</a></li><li class="nav-list-item"><a href="/docs/programming/concurrent-programming/08.%20Decomposition.html" class="nav-list-link">08. Decomposition</a></li><li class="nav-list-item"><a href="/docs/programming/concurrent-programming/09.%20Decomposition%20-%20Task.html" class="nav-list-link">09. Decomposition - Task Parallelism</a></li><li class="nav-list-item"><a href="/docs/programming/concurrent-programming/10.%20Decomposition%20-%20Data.html" class="nav-list-link">10. Decomposition - Data Parallelism</a></li><li class="nav-list-item"><a href="/docs/programming/concurrent-programming/11.%20Synchronization.html" class="nav-list-link">11. Synchronization</a></li><li class="nav-list-item"><a href="/docs/programming/concurrent-programming/12.%20Synchronization%20-%20Mutexes%20and%20Semaphores.html" class="nav-list-link">12. Synchronization - Mutexes and Semaphores</a></li><li class="nav-list-item"><a href="/docs/programming/concurrent-programming/13.%20Synchronization%20-%20Deadlocks.html" class="nav-list-link">13. Synchronization - Deadlock</a></li><li class="nav-list-item"><a href="/docs/programming/concurrent-programming/14.%20Synchronization%20-%20Starvation.html" class="nav-list-link">14. Synchronization - Starvation</a></li><li class="nav-list-item"><a href="/docs/programming/concurrent-programming/15.%20Synchronization%20-%20RWLocks%20and%20Spin%20Locks.html" class="nav-list-link">15. Synchronization - RWLock, Spin Lock</a></li></ul></li><li class="nav-list-item"><a href="/docs/programming/c-cpp" class="nav-list-link">C / C++</a></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Python category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/docs/programming/python" class="nav-list-link">Python</a><ul class="nav-list"><li class="nav-list-item"><a href="/docs/programming/python/01.%20Typing.html" class="nav-list-link">01. Typing</a></li><li class="nav-list-item"><a href="/docs/programming/python/02.%20Decorator.html" class="nav-list-link">02. Decorators</a></li></ul></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Rust category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/docs/programming/rust" class="nav-list-link">Rust</a><ul class="nav-list"><li class="nav-list-item"><a href="/docs/programming/rust/introduction" class="nav-list-link">01. Hello, World!</a></li><li class="nav-list-item"><a href="/docs/programming/rust/basic-syntax" class="nav-list-link">02. Basic Syntax in Rust</a></li><li class="nav-list-item"><a href="/docs/programming/rust/memory-related" class="nav-list-link">03. Pointers in Rust</a></li></ul></li></ul></li><li class="nav-list-item"><a href="/docs/mathematics" class="nav-list-link">Mathematics</a></li><li class="nav-list-item"><a href="/docs/devlog" class="nav-list-link">Devlog</a></li><li class="nav-list-item"><a href="/docs/about.html" class="nav-list-link">About</a></li></ul> <ul class="nav-list"><li class="nav-list-item external"> <a href="https://github.com/Sangdo-Han" class="nav-list-link external" > GitHub <svg viewBox="0 0 24 24" aria-labelledby="svg-external-link-title"><use xlink:href="#svg-external-link"></use></svg> </a> </li></ul> </nav> <footer class="site-footer"> This site uses <a href="https://github.com/just-the-docs/just-the-docs">Just the Docs</a>, a documentation theme for Jekyll. </footer> </div> <div class="main" id="top"> <div id="main-header" class="main-header"> <div class="search" role="search"> <div class="search-input-wrap"> <input type="text" id="search-input" class="search-input" tabindex="0" placeholder="Search sanhan research" aria-label="Search sanhan research" autocomplete="off"> <label for="search-input" class="search-label"><svg viewBox="0 0 24 24" class="search-icon"><use xlink:href="#svg-search"></use></svg></label> </div> <div id="search-results" class="search-results"></div> </div> </div> <div class="main-content-wrap"> <nav aria-label="Breadcrumb" class="breadcrumb-nav"> <ol class="breadcrumb-nav-list"> <li class="breadcrumb-nav-list-item"><a href="/docs/ai-research">AI Research</a></li> <li class="breadcrumb-nav-list-item"><a href="/docs/ai-research/computer-vision">Computer Vision</a></li> <li class="breadcrumb-nav-list-item"><span>3D Image Reconstruction</span></li> </ol> </nav> <div id="main-content" class="main-content"> <main> <h1 id="3d-image-reconstruction"> <a href="#3d-image-reconstruction" class="anchor-heading" aria-labelledby="3d-image-reconstruction"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 3D Image Reconstruction </h1> <details open=""> <summary class="text-delta"> Table of contents </summary> <ul id="markdown-toc"> <li><a href="#3d-image-reconstruction" id="markdown-toc-3d-image-reconstruction">3D Image Reconstruction</a> <ul> <li><a href="#3d-reconstruction---introduction" id="markdown-toc-3d-reconstruction---introduction">3D Reconstruction - Introduction</a> <ul> <li><a href="#backgrounds" id="markdown-toc-backgrounds">Backgrounds</a></li> <li><a href="#datasets-metrics-and-representations" id="markdown-toc-datasets-metrics-and-representations">Datasets, Metrics and Representations</a> <ul> <li><a href="#datasets" id="markdown-toc-datasets">Datasets</a></li> <li><a href="#metrics" id="markdown-toc-metrics">Metrics</a></li> <li><a href="#3d-computer-vision-representation" id="markdown-toc-3d-computer-vision-representation">3D Computer Vision Representation</a></li> </ul> </li> </ul> </li> <li><a href="#references" id="markdown-toc-references">References</a></li> </ul> </li> </ul> </details> <h2 id="3d-reconstruction---introduction"> <a href="#3d-reconstruction---introduction" class="anchor-heading" aria-labelledby="3d-reconstruction---introduction"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 3D Reconstruction - Introduction </h2> <p> Introductions to 3D Reconstruction : Backgrounds, Metrics and Representations</p> <h3 id="backgrounds"> <a href="#backgrounds" class="anchor-heading" aria-labelledby="backgrounds"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Backgrounds </h3> <p>3D reconstruction, which is 3-Dimensional representation of objects, can be used for many applications such as video games, animation, navigation and so on.</p> <p>There are many traditional methods in 3D reconstruction like SfM(Structure from Motion), Dense Reconstruction and MVS(Multi-View Stereo). Those traditional methods are based on photogrammetry.</p> <p>It is true that understanding the basics of photogrammetry is very important to understand deep-learning based 3D reconstruction because deep-learning based methods are built on top of these photogrammetry techniques.</p> <p>In this post, however, it is assumed that the readers have knowledge about deep learning models rather than 3D reconstructions. Hence, the discussion will focus on deep-learning based 3D reconstructions while traditional techniques will be mentioned only as needed for readers to comprehend the deep-learning models.</p> <h3 id="datasets-metrics-and-representations"> <a href="#datasets-metrics-and-representations" class="anchor-heading" aria-labelledby="datasets-metrics-and-representations"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Datasets, Metrics and Representations </h3> <p><strong>Based on 3D reconstruction using deep learning : a survey [<a href="#jin-et-al">1</a>]</strong></p> <p>Starting with a good review paper helps to understand the field and the potential research directions. In deep learning based 3D reconstruction, luckily we can access a good review paper [<a href="#jin-et-al">1</a>] for free.</p> <h4 id="datasets"> <a href="#datasets" class="anchor-heading" aria-labelledby="datasets"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Datasets </h4> <p>The paper[<a href="#jin-et-al">1</a>] show us several useful dataset for 3D reconstructions:</p> <ol> <li> <p><a href="https://shapenet.org/">ShapeNet</a> <br /> It is a very large scale dataset for CAD models developed by Chang et al.[<a href="#shapenet">2</a>] from Stanford University, Princeton University and the Toyota Technological Institute at Chicago, USA.</p> </li> <li> <p><a href="https://cvgl.stanford.edu/projects/pascal3d.html">Pascal3D+</a> <br /> It is a multi-view datasets, if you are familiar with Object Detection Task, you might be heard of PASCAL VOC dataset. Pascal3D+ has 12 categories of rigid object from PASCAL VOC 2012. This dataset is developed by Yu Xiang et al[<a href="#pascal3d">3</a>] from Computational Vision and Geometry Lab at Stanford University.</p> </li> <li> <p><a href="https://cvgl.stanford.edu/projects/objectnet3d/">ObjectNet3D</a><br /> It is a large scale database for 3D objects. Like as Pascal3D+, this dataset is developed by Yu Xiang et al[<a href="#objectnet">4</a>] from Computational Vision and Geometry Lab at Stanford University.</p> </li> <li> <p><a href="https://www.cvlibs.net/datasets/kitti/">KITTI</a><br /> If you are familiar with Computer Vision in automous driving and mobile robotics, I am sure that you heard of this dataset. This was introduced by Andres Geiger et al[<a href="#kitti-dataset">5</a>].</p> </li> </ol> <h4 id="metrics"> <a href="#metrics" class="anchor-heading" aria-labelledby="metrics"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Metrics </h4> <p>The paper[<a href="#jin-et-ßal">1</a>] briefly explains 3 commonly used metric used: MSE, Voxel IoU and cross-entropy. I think the reader might familiar with MSE and cross-entropy. Therefore, I will skip their details.</p> <p><strong><em>Voxel IoU</em></strong></p> <p>In many cases in Computer Vision, IoU represents an abbreviation of Intersection over Union. As you might guess. Voxel IoU is mere volumetric extension of 2D-pixel-IoU. which is:</p> \[{IoU={G \cap P \over G \cup P}}\] <p>Here, G stands for a set of voxels in a ground truth, while P stands for a set of voxels in prediction/reconstruction. This metric is also widely used for 3D object detection or segmentation.</p> <p>Also, for point cloud and mesh representation, sevaral distance metrics between groundtruth and reconstruction can be used as metric. I beleive that readers are familiar with Euclidean Distance, I will post about Chamfer Distance and EMD instead.</p> <p><strong><em>Chamfer Distance</em></strong></p> <p>Chamfer Distance is average of the summation of closest point pairs.</p> \[Chamfer(G,P) = {1\over{n}}(\sum_i \min_j(||g_i - p_j||) + \sum_j \min_i(||g_i - p_j||))\] <p>More precisely, The formula represents average of distance from each point in one point cloud to its closest point in the other point cloud. and vice versa.</p> <p><strong><em>EMD</em></strong></p> <p>Earth mover’s distance (EMD), also known as the Wasserstein distance, stands for the distance between probability distributions over a region in statistics.</p> \[EMD(P, \hat{P})=\min_{\phi:P\rightarrow\hat{P}} \sum_{p_i\in P}||p_i - \phi(p_i)||\] <p>This can be computed using the Hungarian Algorithm or Sinkhorn-Knopp algorithm.</p><hr /> <h4 id="3d-computer-vision-representation"> <a href="#3d-computer-vision-representation" class="anchor-heading" aria-labelledby="3d-computer-vision-representation"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 3D Computer Vision Representation </h4> <p>The original survey [<a href="#jin-et-al">1</a>] divides the reconstruction techniques into two main categories by the number of sources. (Reconstruction based on single image or multiple images.) After that, it lists up middle categories with way of representations or how outcome look like with a short descriptions.</p> <p>These could be very helpful for the researchers who are familiar with 3D Computer Vision. However, for the newcomers (I assume that most of readers of survey papers are newcomers), I think that it would be more effective writing if it explains the ways of representing 3D object first, and then explains the models and results.</p> <p><strong><em>Voxel Representation</em></strong></p> <p>Voxel is a volumetric representation which can be comparing to pixel representation in 2D images. Actually, by adding depth (D) into pixel, Voxel achieves representation of 3D.</p> <p>\(pixel : H \times W \times C\) \(voxel : H \times W \times D \times C\) \(, where \ H : height , \ W : width, \ D : depth, \ C : channel \ (color)\)</p> <p><strong><em>Point Cloud Representation</em></strong></p> <p>Point Cloud is another way to represent 3D object. A single point cloud is a collection of 3D points (mostly a collection of Cartesian coordinate positions) :</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">point_cloud</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">[</span><span class="n">x1</span><span class="p">,</span> <span class="n">y1</span><span class="p">,</span> <span class="n">z1</span><span class="p">],</span>
    <span class="p">[</span><span class="n">x2</span><span class="p">,</span> <span class="n">y2</span><span class="p">,</span> <span class="n">z2</span><span class="p">],</span>
    <span class="p">...</span>
    <span class="p">[</span><span class="n">xN</span><span class="p">,</span> <span class="n">yN</span><span class="p">,</span> <span class="n">zN</span><span class="p">]</span>
<span class="p">]</span>
</code></pre></div></div> <p><strong><em>Mesh Representation</em></strong></p> <p>Mesh representation could be another option. Mesh is a collection of base geometry to represent surface. Since the least number of points to construct a surface is 3 (triangle), triangle is widely used for mesh representations:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">mesh_representation</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">[</span><span class="n">point_1</span><span class="p">,</span> <span class="n">point_2</span><span class="p">,</span> <span class="n">point_3</span><span class="p">],</span>
    <span class="p">[</span><span class="n">point_4</span><span class="p">,</span> <span class="n">point_5</span><span class="p">,</span> <span class="n">point_6</span><span class="p">],</span>
    <span class="p">...</span>
    <span class="p">[</span><span class="n">point_a</span><span class="p">,</span> <span class="n">point_b</span><span class="p">,</span> <span class="n">point_c</span><span class="p">]</span>
<span class="p">]</span>
</code></pre></div></div> <p>Each point (vertex) represents 3d point (x,y,z)</p> <p><strong><em>Other Representation</em></strong></p> <p><em>Implicit Surface</em></p> <p>Implicit Surface is a model based surface representation. Models can be a continuous decision boundary of deeplearning network classifiers, suggested in OccNet<a href="#OccNet">6</a>, or multi-layer network architecture to extract geometry features and represents 3D shapes in an Euclidean preserving latent space as in UCLID-Net<a href="#EUCLID-Net">7</a> This concept is novel but thinking of the mathematics, we can easily see the concepts:</p> \[f_{model}(x,y,z) = 0\] <p>which resembles our well-known implicit surface:</p> \[f(x,y,z) = x^2+y^2+z^2 -1 =0\] <p>a sphere!</p> <p><em>depth</em></p> <p>About generating depths based on a 2D images, 3D representation also be achieved.</p> <h2 id="references"> <a href="#references" class="anchor-heading" aria-labelledby="references"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> References </h2> <p><span id="jin-et-al">[1]</span> Jin, Y., Jiang, D., &amp; Cai, M. (2020). 3d reconstruction using deep learning: a survey. Communications in Information and Systems, 20(4), 389-413.</p> <p><span id="shapenet">[2]</span> Chang, A. X., Funkhouser, T., Guibas, L., Hanrahan, P., Huang, Q., Li, Z., … &amp; Yu, F. (2015). Shapenet: An information-rich 3d model repository. arXiv preprint arXiv:1512.03012.</p> <p><span id="pascal3d">[3]</span> Y. Xiang, R. Mottaghi and S. Savarese, “Beyond PASCAL: A benchmark for 3D object detection in the wild,” IEEE Winter Conference on Applications of Computer Vision, Steamboat Springs, CO, USA, 2014, pp. 75-82, doi: 10.1109/WACV.2014.6836101.</p> <p><span id="objectnet">[4]</span> Xiang, Y., Kim, W., Chen, W., Ji, J., Choy, C., Su, H., … &amp; Savarese, S. (2016). Objectnet3d: A large scale database for 3d object recognition. In Computer Vision–ECCV 2016: 14th European Conference, Amsterdam, The Netherlands, October 11-14, 2016, Proceedings, Part VIII 14 (pp. 160-176). Springer International Publishing.</p> <p><span id="kitti-dataset">[5]</span> A. Geiger, P. Lenz and R. Urtasun, “Are we ready for autonomous driving? The KITTI vision benchmark suite,” 2012 IEEE Conference on Computer Vision and Pattern Recognition, Providence, RI, USA, 2012, pp. 3354-3361, doi: 10.1109/CVPR.2012.6248074.</p> <p><span id="OccNet">[6]</span> L. Mescheder, M. Oechsle, M. Niemeyer, S. Nowozin, and A. Geiger, “Occupancy networks: Learning 3d reconstruction in function space,” in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2019, pp. 4460–4470.</p> <p><span id="EUCLID-Net">[7]</span> L. Mescheder, M. Oechsle, M. Niemeyer, S. Nowozin, and A. Geiger, “Occupancy networks: Learning 3d reconstruction in function space,” in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2019, pp. 4460–4470.</p> </main> <hr> <footer> <p><a href="#top" id="back-to-top">Back to top</a></p> <div class="d-flex mt-2"> </div> </footer> </div> </div> <div class="search-overlay"></div> </div> <script src="https://cdn.jsdelivr.net/npm/mermaid@9.1.6/dist/mermaid.min.js"></script> <script> var config = {} ; mermaid.initialize(config); window.mermaid.init(undefined, document.querySelectorAll('.language-mermaid')); </script> </body> </html>
